{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/FormationUnivAngers/blob/main/Jour1/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Weeds vs plants Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "\n",
        "## Specific concepts that will be covered:\n",
        "In the process, we will build practical experience and develop intuition around the following concepts\n",
        "\n",
        "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class — How can we efficiently work with data on disk to interface with our model?\n",
        "\n",
        "\n",
        "## We will follow the general machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build our model\n",
        "4. Train our model\n",
        "5. Test our model\n",
        "6. Improve our model/Repeat the process\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Before you begin**\n",
        "\n",
        "Before running the code in this notebook, reset the runtime by going to **Kernel -> Restart & clear output** in the menu above. If you have been working through several notebooks, this will help you avoid reaching memory limits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "Let's start by importing required packages:\n",
        "\n",
        "*   os — to read files and directory structure\n",
        "*   numpy — for some matrix math outside of TensorFlow\n",
        "*   matplotlib.pyplot — to plot the graph and display images in our training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtPGh2MAVrVa"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in3OdvpUG_9_"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ede3_kbeHOjR"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "import numpy as np   # Package for scientific computing\n",
        "import matplotlib.pyplot as plt # 2D plotting library\n",
        "import os     # Using operating system\n",
        "import cv2    # Computer vision and machine learning software library\n",
        "from tqdm import tqdm   # Progress bar library\n",
        "import random  # Generating Random Numbers\n",
        "import pickle # Serializing and de-serializing a Python object structure\n",
        "from os.path import join as pj # for path ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z-8RPSC1fIr"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYwWvirp1fIs"
      },
      "source": [
        "To build our image classifier, we begin by loading the dataset. The dataset we are using is a consists of weeds and plants).\n",
        "\n",
        "In this notebook, we will make use of the class `tf.keras.preprocessing.image.ImageDataGenerator` which will read data from disk. We therefore need to directly of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-NN4VfZ1fIx"
      },
      "source": [
        "We'll now assign variables with the proper file path for the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63dcV5LvwdzO"
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/gdrive/'\n",
        "drive.mount( root )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY6VdK9kxMZU"
      },
      "source": [
        "# create permanent directory in gdrive\n",
        "data_dir_path = r'/My Drive/FormationUA/'\n",
        "os.makedirs(root+data_dir_path, exist_ok=True)\n",
        "os.listdir(root+data_dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSupZ0j1w1DF"
      },
      "source": [
        "!unzip -q \"/content/gdrive/My Drive/FormationUA/data.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ET8KoCi0ld1"
      },
      "source": [
        "ls data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymZLg7kq1fIy"
      },
      "source": [
        "base_dir = 'data'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utv3nryxVrV0"
      },
      "source": [
        "train_weeds_dir = os.path.join(train_dir, 'weeds')  # directory with our training weed pictures\n",
        "train_plants_dir = os.path.join(train_dir, 'plants')  # directory with our training plant pictures\n",
        "validation_weeds_dir = os.path.join(validation_dir, 'weeds')  # directory with our validation weed pictures\n",
        "validation_plants_dir = os.path.join(validation_dir, 'plants')  # directory with our validation plant pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdrHHTy2VrV3"
      },
      "source": [
        "### Understanding our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "Let's look at how many plants and weeds images we have in our training and validation directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc4u8e9hVrV4"
      },
      "source": [
        "num_weeds_tr = len(os.listdir(train_weeds_dir))\n",
        "num_plants_tr = len(os.listdir(train_plants_dir))\n",
        "\n",
        "num_weeds_val = len(os.listdir(validation_weeds_dir))\n",
        "num_plants_val = len(os.listdir(validation_plants_dir))\n",
        "\n",
        "total_train = num_weeds_tr + num_plants_tr\n",
        "total_val = num_weeds_val + num_plants_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4GGzGt0VrV7"
      },
      "source": [
        "print('total training weeds images:', num_weeds_tr)\n",
        "print('total training plants images:', num_plants_tr)\n",
        "\n",
        "print('total validation weeds images:', num_weeds_val)\n",
        "print('total validation plants images:', num_plants_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC8fIsalVrXd"
      },
      "source": [
        "# Reading Data\n",
        "\n",
        "Here, we read and have applied normalization to our training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnr2xujaVrXe"
      },
      "source": [
        "IMG_SIZE_H=256 # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "IMG_SIZE_W=256 # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "def read_data(DATADIR):\n",
        "  input_data = []\n",
        "  CATEGORIES = os.listdir(DATADIR) \n",
        "  for category in CATEGORIES:  # do plants and weeds\n",
        "\n",
        "      path = os.path.join(DATADIR,category)  # create path to the labels\n",
        "      class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=plants 1=weeds\n",
        "\n",
        "      for img in tqdm(os.listdir(path)):  # iterate over each image per plants and weeds\n",
        "      \n",
        "          img_array = cv2.imread(os.path.join(path,img))  # convert to array \n",
        "          new_array = cv2.resize(img_array, (IMG_SIZE_H, IMG_SIZE_W))  # resize to normalize data size\n",
        "          input_data.append([new_array, class_num])  # add this to our training_data\n",
        "  \n",
        "  \n",
        "  return input_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goG3S3883ynl"
      },
      "source": [
        "training_data = read_data(train_dir)  # Calling the function for reading Training images and labels\n",
        "Validation_data = read_data(validation_dir)  # Calling the function for reading Training images and labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxtRaTrW5how"
      },
      "source": [
        "**Preparation of data for feeding into a CNN model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65tqTeWu5s1s"
      },
      "source": [
        "random.shuffle(training_data)   # Shuffling data \n",
        "random.shuffle(Validation_data)   # Shuffling data \n",
        "X = []  # An Array for Training images\n",
        "y = []  # An Array for Training labels\n",
        "X_val = []  # An Array for Validation images\n",
        "y_val = []  # An Array for Validation labels\n",
        "\n",
        "for features,label in training_data:   # Seperation of iamegs and labels\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "print(\"Total training images:\",np.array(X).shape) # Print the size of the database\n",
        "\n",
        "for features,label in Validation_data:   # Seperation of iamegs and labels\n",
        "    X_val.append(features)\n",
        "    y_val.append(label)\n",
        "print(\"Total validation images:\", np.array(X_val).shape) # Print the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St2KJvZj9b0u"
      },
      "source": [
        "X = np.array(X).reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 3)  # Reshape data in a form that is suitable for keras\n",
        "X_val = np.array(X_val).reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 3)  # Reshape data in a form that is suitable for keras\n",
        "print(X.shape) # Print the size of the database\n",
        "print(X_val.shape) # Print the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW-pV5awVrXl"
      },
      "source": [
        "Let's visualize how a single image would look like five different times, when we pass these augmentations randomly to our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2m68eMhVrXm"
      },
      "source": [
        "# plot 3 images as gray scale\n",
        "plt.subplot(131)\n",
        "plt.imshow(cv2.cvtColor(X[0,:,:,:], cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(132)\n",
        "plt.imshow(cv2.cvtColor(X[20,:,:,:], cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(133)\n",
        "plt.imshow(cv2.cvtColor(X[100,:,:,:], cv2.COLOR_BGR2RGB)) \n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdsI_L-NVrV_"
      },
      "source": [
        "# Setting Model Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "The model consists of four convolution blocks with a max pool layer in each of them.\n",
        "\n",
        "Before the final Dense layers, we're also applying a Dropout probability of 0.5. It means that 50% of the values coming into the Dropout layer will be set to zero. This helps to prevent overfitting.\n",
        "\n",
        "Then we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes — plants and weeds — using `softmax`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Evjf8jZk2zi-"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADWLqMSJcH3"
      },
      "source": [
        "### Compiling the model\n",
        "\n",
        "As usual, we will use the `adam` optimizer. Since we output a softmax categorization, we'll use `sparse_categorical_crossentropy` as the loss function. We would also like to look at training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08rRJ0sn3Tb1"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uurnCp_H4Hj9"
      },
      "source": [
        "### Model Summary\n",
        "\n",
        "Let's look at all the layers of our network using **summary** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b66qAJF_4Jnw"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "It's time we train our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR31ks0Z1fKH"
      },
      "source": [
        "# saving the log and show it by tensorboard\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbcCNN=TensorBoardColab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5NT1PW3j_P"
      },
      "source": [
        "history = model.fit(\n",
        "    X, y, \n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100, batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[TensorBoardColabCallback(tbcCNN)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyX2Klo0p-I7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
